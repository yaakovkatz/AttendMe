from ultralytics import YOLO
from deepface import DeepFace
from tensorflow.keras import Model, Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Lambda, BatchNormalization
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dropout
import tensorflow as tf
import numpy as np
import cv2
import os
import glob
import shutil
from tabulate import tabulate  # ×”×•×¡×¤×ª ×”×¡×¤×¨×™×™×” ×œ×˜×‘×œ×”
import contextlib
import io

# ×™×™×‘×•× ××”××•×“×•×œ ×”×—×“×©
from face_extraction import FaceExtractor, print_status

FIRST_THRESHOLD = 0.5
SECOND_THRESHOLD = 0.3
# ×”×¡×¨×ª THIRD_THRESHOLD = 0.65
FACE_SIZE_THRESHOLD = 0.000
MIN_SHARPNESS = 000
MAX_NOISE_THRESHOLD = 100
MIN_CONTRAST = 0.0

# ============================================================================

import requests
import tempfile
import contextlib
import os

@contextlib.contextmanager
def temp_image_from_url(image_url):
    """Downloads an image from a URL to a temporary file and yields the path."""
    temp_file_path = None
    try:
        response = requests.get(image_url, stream=True)
        response.raise_for_status()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
            for chunk in response.iter_content(8192):
                temp_file.write(chunk)
            temp_file_path = temp_file.name
        yield temp_file_path
    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)


class FaceDetection:
    def __init__(self, target_image_path="target.jpg"):
        print_status("×××ª×—×œ ××¢×¨×›×ª ×–×™×”×•×™ ×¤× ×™×...", emoji="ğŸš€")
        self.yolo_model = YOLO('./face_yolov8n.pt')
        self.enviro_faces_dir = "./EnviroFaces"

        # ×™×¦×™×¨×ª ××•×¤×¢ ×©×œ ××—×œ×¥ ×”×¤× ×™×
        self.face_extractor = FaceExtractor(model_path='./face_yolov8n.pt', output_dir=self.enviro_faces_dir)

        # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×××’×¨ ×× ×œ× ×§×™×™××ª
        if not os.path.exists(self.enviro_faces_dir):
            os.makedirs(self.enviro_faces_dir)
            print_status(f"× ×•×¦×¨×” ×ª×™×§×™×™×ª ×××’×¨ ×¤× ×™× ×—×“×©×”: {self.enviro_faces_dir}", level=1, emoji="ğŸ“")

    # ==================================================================================
    """×××™×¨ ×¢×¨×›×™ ×“××™×•×Ÿ ×œ×˜×•×•×— ×ª×§×™×Ÿ ×©×œ 0 ×¢×“ 1 ×¢×¨×›×™× ×©×œ×™×œ×™×™× ×”×•×¤×›×™× ×œ-0 """
    # ==================================================================================
    def normalize_similarity_score(self, value):

        if isinstance(value, str):
            # ×‘××§×¨×” ×©×”×¢×¨×š ××’×™×¢ ×›××—×¨×•×–×ª ×¢× %
            try:
                value = float(value.strip('%')) / 100
            except ValueError:
                return 0.0

        # ×”××¨×ª ×¢×¨×›×™× ×©×œ×™×œ×™×™× ×œ-0
        if value < 0:
            return 0.0
        # ×”×’×‘×œ×ª ×¢×¨×›×™× ××¢×œ 1 ×œ-1
        elif value > 1:
            return 1.0
        else:
            return value

    # ==================================================================================
    "××—×™×§×ª ×›×œ ×”×§×‘×¦×™× ××ª×™×§×™×™×” ×œ×¤×™ × ×ª×™×‘ ×©×”×ª×§×‘×œ"
    # ==================================================================================
    def clear_directory(self, directory_path):
        try:
            # ×‘×“×™×§×” ×©×”×ª×™×§×™×™×” ×§×™×™××ª
            if not os.path.exists(directory_path):
                print_status(f"×”×ª×™×§×™×™×” {directory_path} ×œ× ×§×™×™××ª", emoji="âŒ")
                return

            # ××—×™×§×ª ×›×œ ×”×§×‘×¦×™× ×‘×ª×™×§×™×™×”
            files = glob.glob(f"{directory_path}/*.*")  # ×ª×•××š ×‘×›×œ ×¡×•×’×™ ×”×§×‘×¦×™×, ×œ× ×¨×§ jpg

            if not files:
                print_status(f"×”×ª×™×§×™×™×” {directory_path} ×¨×™×§×”", emoji="ğŸ“‚")
                return

            print_status(f"××•×—×§ {len(files)} ×§×‘×¦×™× ××ª×™×§×™×™×” {os.path.basename(directory_path)}", emoji="ğŸ—‘ï¸")

            for file in files:
                try:
                    os.remove(file)
                    print_status(f"× ××—×§: {os.path.basename(file)}", level=1, emoji="âœ“")
                except Exception as e:
                    print_status(f"×©×’×™××” ×‘××—×™×§×ª {os.path.basename(file)}: {str(e)}", level=1, emoji="âš ï¸")

            print_status(f"×”×¡×ª×™×™××” ××—×™×§×ª {len(files)} ×§×‘×¦×™× ×‘×”×¦×œ×—×”", emoji="âœ…")

        except Exception as e:
            print_status(f"×©×’×™××” ×‘× ×™×§×•×™ ×”×ª×™×§×™×™×”: {str(e)}", emoji="âŒ")

    # ==================================================================================
    "××¢×‘×™×¨ ××ª ×”×§×¨×™××” ×œ××•×“×•×œ ×”×—×™×¦×•× ×™"
    # ==================================================================================
    def extract_faces_from_directory(self, directory_path):

        return self.face_extractor.extract_faces_from_directory(directory_path)

    # ==================================================================================
        """×‘×“×™×§×ª ×“××™×•×Ÿ ×‘×™×Ÿ × ×§×•×“×•×ª ×¦×™×•×Ÿ ×‘×¤× ×™× - ××—×œ×™×¤×” ××ª ×‘×“×™×§×ª ×™×—×¡ ×”×¨×•×—×‘ ×”××§×•×¨×™×ª"""
    # ==================================================================================
    def check_face_width_ratio(self, face_image1, face_image2, img1_path=None, img2_path=None, threshold=0.90):
        try:
            # ×œ×™×™×‘× ××ª ×”×¡×¤×¨×™×™×” ×”× ×“×¨×©×ª
            import dlib
            from scipy.spatial.distance import cosine

            # ×”×“×¤×¡×ª ××™×“×¢ ×¢×œ ×”×‘×“×™×§×”
            face1_name = os.path.basename(img1_path) if img1_path else "×ª××•× ×” 1"
            face2_name = os.path.basename(img2_path) if img2_path else "×ª××•× ×” 2"
            print_status(f"×‘×•×“×§ ×”×ª×××ª × ×§×•×“×•×ª ×¦×™×•×Ÿ: {face1_name} ××•×œ {face2_name}", level=1)

            # ×˜×¢×™× ×ª ×’×œ××™ × ×§×•×“×•×ª ×¦×™×•×Ÿ ×©×œ dlib
            detector = dlib.get_frontal_face_detector()
            predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

            # ××™×ª×•×¨ × ×§×•×“×•×ª ×¦×™×•×Ÿ ×‘×ª××•× ×” 1 - ×¢× ×§×“×-×¢×™×‘×•×“ ××©×•×¤×¨
            gray1 = cv2.cvtColor(face_image1, cv2.COLOR_BGR2GRAY)
            gray1 = cv2.equalizeHist(gray1)
            gray1 = cv2.GaussianBlur(gray1, (3, 3), 0)
            gray1 = cv2.resize(gray1, (0, 0), fx=1.5, fy=1.5)

            faces1 = detector(gray1, 1)

            if not faces1:
                print_status(f"×œ× ×–×•×”×• ×¤× ×™× ×‘×ª××•× ×” ×‘×©×œ×‘ ×‘×“×™×§×ª ×”××‘× ×”: {face1_name}", level=1, emoji="â„¹ï¸")
                return "NO_FACE_DETECTED"

            # ××™×ª×•×¨ × ×§×•×“×•×ª ×¦×™×•×Ÿ ×‘×ª××•× ×” 2 - ×¢× ××•×ª×• ×§×“×-×¢×™×‘×•×“
            gray2 = cv2.cvtColor(face_image2, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.equalizeHist(gray2)
            gray2 = cv2.GaussianBlur(gray2, (3, 3), 0)
            gray2 = cv2.resize(gray2, (0, 0), fx=1.5, fy=1.5)

            faces2 = detector(gray2, 1)

            if not faces2:
                print_status(f"×œ× ×–×•×”×• ×¤× ×™× ×‘×ª××•× ×” ×‘×©×œ×‘ ×‘×“×™×§×ª ×”××‘× ×”: {face2_name}", level=1, emoji="â„¹ï¸")
                return "NO_FACE_DETECTED"

            # ×”×§×•×“ ×”××§×•×¨×™ ×œ×”×©×•×•××ª × ×§×•×“×•×ª ×¦×™×•×Ÿ
            landmarks1 = predictor(gray1, faces1[0])
            landmarks2 = predictor(gray2, faces2[0])

            # ×”××¨×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ ×œ××¢×¨×š
            landmarks1_array = np.array([[landmarks1.part(i).x, landmarks1.part(i).y] for i in range(68)])
            landmarks2_array = np.array([[landmarks2.part(i).x, landmarks2.part(i).y] for i in range(68)])

            # × ×¨××•×œ ×”× ×§×•×“×•×ª (×œ×”×¤×—×ª×ª ×”×©×¤×¢×•×ª ×’×•×“×œ ×•×¡×™×‘×•×‘)
            landmarks1_norm = landmarks1_array - np.mean(landmarks1_array, axis=0)
            landmarks2_norm = landmarks2_array - np.mean(landmarks2_array, axis=0)

            # ×—×œ×•×§×” ×œ××–×•×¨×™× ×× ×˜×•××™×™×
            # ×¢×™× ×™×™×: × ×§×•×“×•×ª 36-47
            eyes_1 = landmarks1_norm[36:48]
            eyes_2 = landmarks2_norm[36:48]

            # ××£: × ×§×•×“×•×ª 27-35
            nose_1 = landmarks1_norm[27:36]
            nose_2 = landmarks2_norm[27:36]

            # ×¤×”: × ×§×•×“×•×ª 48-67
            mouth_1 = landmarks1_norm[48:68]
            mouth_2 = landmarks2_norm[48:68]

            # ×§×• ×œ×¡×ª: × ×§×•×“×•×ª 0-16
            jaw_1 = landmarks1_norm[0:17]
            jaw_2 = landmarks2_norm[0:17]

            # ×—×™×©×•×‘ ×“××™×•×Ÿ ×œ×›×œ ××–×•×¨
            eyes_sim = 1 - cosine(eyes_1.flatten(), eyes_2.flatten())
            nose_sim = 1 - cosine(nose_1.flatten(), nose_2.flatten())
            mouth_sim = 1 - cosine(mouth_1.flatten(), mouth_2.flatten())
            jaw_sim = 1 - cosine(jaw_1.flatten(), jaw_2.flatten())

            # ×—×™×©×•×‘ ×“××™×•×Ÿ ×›×•×œ×œ - ×©×§×œ×•×œ ×¢× ×“×’×© ×¢×œ ×”×¢×™× ×™×™× ×•×”××£
            similarity = (eyes_sim * 0.35 + nose_sim * 0.35 + mouth_sim * 0.15 + jaw_sim * 0.15)

            # ×—×™×©×•×‘ ×™×—×¡×™× ××‘× ×™×™× ×—×©×•×‘×™×
            eye_distance_1 = np.linalg.norm(landmarks1_norm[36] - landmarks1_norm[45])
            eye_distance_2 = np.linalg.norm(landmarks2_norm[36] - landmarks2_norm[45])

            nose_length_1 = np.linalg.norm(landmarks1_norm[27] - landmarks1_norm[33])
            nose_length_2 = np.linalg.norm(landmarks2_norm[27] - landmarks2_norm[33])

            # ×™×—×¡ ×¢×™× ×™×™×-××£
            eye_nose_ratio_1 = eye_distance_1 / (nose_length_1 + 1e-6)  # ×× ×™×¢×ª ×—×œ×•×§×” ×‘××¤×¡
            eye_nose_ratio_2 = eye_distance_2 / (nose_length_2 + 1e-6)

            # ×‘×“×™×§×ª ×”×‘×“×œ ×‘×™×—×¡×™×
            ratio_diff = abs(eye_nose_ratio_1 - eye_nose_ratio_2)

            # ×”×¤×—×ª×” ××”×“××™×•×Ÿ ×× ×”×™×—×¡×™× ×©×•× ×™× ××“×™
            if ratio_diff > 0.2:  # ×”×‘×“×œ ×©×œ ×™×•×ª×¨ ×-20% ×‘×™×—×¡
                similarity = similarity * (1 - ratio_diff)

            result = similarity >= threshold

            # ×”×“×¤×¡×ª ××™×“×¢ ××¤×•×¨×˜ ×¢×œ ×”×”×©×•×•××”
            if result:
                print_status(f"×”×ª×××ª × ×§×•×“×•×ª ×¦×™×•×Ÿ ×˜×•×‘×”: {similarity:.2%}", level=1, emoji="âœ…")
                print_status(f"×“××™×•×Ÿ ×œ×¤×™ ××–×•×¨×™× - ×¢×™× ×™×™×: {eyes_sim:.2%}, ××£: {nose_sim:.2%}, ×¤×”: {mouth_sim:.2%}",
                             level=2)
            else:
                print_status(f"×”×ª×××ª × ×§×•×“×•×ª ×¦×™×•×Ÿ ×—×œ×©×”: {similarity:.2%}", level=1, emoji="âš ï¸")
                print_status(f"×“××™×•×Ÿ ×œ×¤×™ ××–×•×¨×™× - ×¢×™× ×™×™×: {eyes_sim:.2%}, ××£: {nose_sim:.2%}, ×¤×”: {mouth_sim:.2%}",
                             level=2)

            return result

        except Exception as e:
            print_status(f"×©×’×™××” ×‘×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ: {str(e)}", level=1, emoji="âŒ")
            return False

# ==================================================================================
            """×¤×•× ×§×¦×™×” ×œ×”×©×•×•××ª ×©×ª×™ ×ª××•× ×•×ª ×¤× ×™×"""
# ==================================================================================
    def verify_face(self, img1_path, img2_path):
        try:
            result = DeepFace.verify(
                img1_path=img1_path,
                img2_path=img2_path,
                enforce_detection=False,
                detector_backend='retinaface',
                model_name='Facenet512',
                distance_metric='cosine',
                align=True
            )
            return 1 - result['distance']
        except Exception as e:
            print_status(f"×©×’×™××” ×‘×”×©×•×•××ª ×¤× ×™×: {str(e)}", level=1, emoji="âš ï¸")
            return 0

    def verify_face_second(self, img1_path, img2_path):
        """×¤×•× ×§×¦×™×” ×©× ×™×™×” ×œ×”×©×•×•××ª ×¤× ×™× - ××©×ª××©×ª ×‘DeepFace ×¢× ××•×“×œ ××—×¨"""
        try:
            result = DeepFace.verify(
                img1_path=img1_path,
                img2_path=img2_path,
                enforce_detection=False,
                detector_backend='retinaface',
                model_name='VGG-Face',  # ××•×“×œ ×©×•× ×” ××”×¨××©×•×Ÿ
                distance_metric='cosine',
                align=True
            )
            return 1 - result['distance']
        except Exception as e:
            print_status(f"×©×’×™××” ×‘×”×©×•×•××ª ×¤× ×™× ×©× ×™×™×”: {str(e)}", level=1, emoji="âš ï¸")
            return 0

    # ==================================================================================
        """Runs DeepFace verification on two images from URLs."""
    # ==================================================================================
    def verify_face_from_urls(self, img1_url, img2_url):

        try:
            with temp_image_from_url(img1_url) as temp_img1_path:
                with temp_image_from_url(img2_url) as temp_img2_path:
                    # ×§×¨×™××” ×œ-DeepFace ×¢× ×”× ×ª×™×‘×™× ×”×–×× ×™×™×
                    result = DeepFace.verify(
                        img1_path=temp_img1_path,
                        img2_path=temp_img2_path,
                        enforce_detection=False,
                        detector_backend='retinaface',
                        model_name='Facenet512',
                        distance_metric='cosine',
                        align=True
                    )
                    return 1 - result['distance']
        except Exception as e:
            print_status(f"×©×’×™××” ×‘×”×©×•×•××ª ×¤× ×™× ×-URL: {str(e)}", level=1, emoji="âš ï¸")
            return 0


# ==================================================================================
    """×‘×“×™×§×ª ×”×ª×××” ××¢××™×§×” ×œ××§×¨×™× ×’×‘×•×œ×™×™× ×¢× 4 ×’×™×©×•×ª ×©×•× ×•×ª ×›×•×œ×œ × ×§×•×“×•×ª ×¦×™×•×Ÿ"""
# ==================================================================================
    def perform_enhanced_verification(self, img1_path, img2_path):
        try:
            # ×’×™×©×” 1: ×”××§×•×¨×™×ª ×¢× × ×•×¨××œ×™×–×¦×™×”
            try:
                result1 = DeepFace.verify(
                    img1_path=img1_path,
                    img2_path=img2_path,
                    enforce_detection=False,
                    detector_backend='retinaface',
                    model_name='Facenet512',
                    distance_metric='cosine',
                    align=True,
                    normalization='base'
                )
                sim1 = 1 - result1['distance']
                print_status(f"âœ… ×’×™×©×” 1 (retinaface/cosine): ×¦×™×•×Ÿ ×“××™×•×Ÿ {self.normalize_similarity_score(sim1):.2f}", level=2)
            except Exception as e:
                sim1 = 0.0
                print_status(f"âŒ ×’×™×©×” 1 (retinaface/cosine): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim1:.4f}", level=2)

            # ×’×™×©×” 2: ××˜×¨×™×§×ª ××¨×—×§ ×©×•× ×”
            try:
                result2 = DeepFace.verify(
                    img1_path=img1_path,
                    img2_path=img2_path,
                    enforce_detection=False,
                    detector_backend='retinaface',
                    model_name='Facenet512',
                    distance_metric='euclidean_l2',
                    align=True
                )
                sim2 = 1 - result2['distance']
                print_status(f"âœ… ×’×™×©×” 2 (retinaface/euclidean_l2): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim2:.4f}", level=2)
            except Exception as e:
                sim2 = 0.0
                print_status(f"âŒ ×’×™×©×” 2 (retinaface/euclidean_l2): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim2:.4f}", level=2)

            # ×’×™×©×” 3: ×× ×•×¢ ×–×™×”×•×™ ×©×•× ×” ×œ×’××¨×™
            try:
                result3 = DeepFace.verify(
                    img1_path=img1_path,
                    img2_path=img2_path,
                    enforce_detection=False,
                    detector_backend='mtcnn',  # ×©×™× ×•×™ ×× ×•×¢ ×–×™×”×•×™ ×œ×’××¨×™
                    model_name='Facenet512',
                    distance_metric='cosine',
                    align=True
                )
                sim3 = 1 - result3['distance']
                print_status(f"âœ… ×’×™×©×” 3 (mtcnn/cosine): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim3:.4f}", level=2)
            except Exception as e:
                sim3 = 0.0
                print_status(f"âŒ ×’×™×©×” 3 (mtcnn/cosine): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim3:.4f}", level=2)

            # ×’×™×©×” 4: ×©×™××•×© ×‘-VGG-Face ×¢× ×’×œ××™ ×•×”×’×“×¨×•×ª ××—×¨×•×ª
            try:
                result4 = DeepFace.verify(
                    img1_path=img1_path,
                    img2_path=img2_path,
                    enforce_detection=False,
                    detector_backend='opencv',  # ×©×™××•×© ×‘-OpenCV ×‘××§×•× retinaface/mtcnn
                    model_name='VGG-Face',  # ××•×“×œ ×©×›× ×¨××” ×›×‘×¨ ××•×ª×§×Ÿ
                    distance_metric='euclidean',
                    align=True
                )
                sim4 = 1 - result4['distance']
                print_status(f"âœ… ×’×™×©×” 4 (opencv/VGG-Face/euclidean): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim4:.4f}", level=2)
            except Exception as e:
                sim4 = 0.0
                print_status(f"âŒ ×’×™×©×” 4 (opencv/VGG-Face/euclidean): ×¦×™×•×Ÿ ×“××™×•×Ÿ {sim4:.4f}", level=2)

            # ×”×—×œ×˜×” ×”×× ×œ×›×œ×•×œ ××ª ×’×™×©×” 4 ×‘×©×§×œ×•×œ ×”×¡×•×¤×™
            # ×ª××™×“ ×›×œ×•×œ ××ª ×’×™×©×” 4 ×‘×©×§×œ×•×œ, ×‘×œ×™ ×ª× ××™
            if sim4 < 0:
                # ×× ×”×¢×¨×š ×©×œ×™×œ×™, ×”×¤×•×š ××•×ª×• ×œ×—×™×•×‘×™ ××‘×œ ×ª×Ÿ ×œ×• ××©×§×œ × ××•×š ×™×•×ª×¨
                sim4_adjusted = abs(sim4) * 0.5  # ×œ××©×œ, ×—×¦×™ ××”×¢×¨×š ×”××•×—×œ×˜
            else:
                sim4_adjusted = sim4

            # ×©×§×œ×•×œ ×¢× ×›×œ 4 ×”×’×™×©×•×ª ×ª××™×“
            final_score = (sim1 * 0.3) + (sim2 * 0.1) + (sim3 * 0.3) + (sim4_adjusted * 0.3)
            print_status(f"ğŸ“Š ×¦×™×•×Ÿ ×¡×•×¤×™ ××©×•×§×œ×œ (×¢× ×›×œ 4 ×”×’×™×©×•×ª): {final_score:.4f}", level=1)

            return final_score

        except Exception as e:
            print_status(f"âš ï¸ ×©×’×™××” ×‘×‘×“×™×§×” ××¢××™×§×”: {str(e)}", level=1)
            return 0

# ==================================================================================
    """×‘×™×¦×•×¢ ×‘×“×™×§×” ××¢××™×§×” ×œ×ª××•× ×•×ª ×¤×•×˜× ×¦×™××œ×™×•×ª ×©×œ× ×¢×‘×¨×• ××ª ×”×¡×£ ×”×¨×’×™×œ"""
# ==================================================================================
    def perform_deep_analysis(self, personal_image_path, potential_matches):
        """
        ×‘×™×¦×•×¢ ×‘×“×™×§×” ××¢××™×§×” ×œ×ª××•× ×•×ª ×¤×•×˜× ×¦×™××œ×™×•×ª ×©×œ× ×¢×‘×¨×• ××ª ×”×¡×£ ×”×¨×’×™×œ

        Args:
            personal_image_path: × ×ª×™×‘ ×œ×ª××•× ×” ×”××™×©×™×ª ×©× ×‘×“×§×ª
            potential_matches: ×¨×©×™××” ×©×œ ×˜××¤×œ×™× (× ×ª×™×‘_×œ×ª××•× ×”, ×¦×™×•×Ÿ_×“××™×•×Ÿ) ×œ×‘×“×™×§×” ××¢××™×§×”

        Returns:
            list: ×¨×©×™××ª × ×ª×™×‘×™× ×œ×ª××•× ×•×ª ×©×¢×‘×¨×• ××ª ×”×‘×“×™×§×” ×”××¢××™×§×”
        """

        if not potential_matches:
            return []

        print_status(f"× ××¦××• {len(potential_matches)} ×¤× ×™× ×©×“×•×¨×©×•×ª ×‘×“×™×§×” ××¢××™×§×”:", emoji="ğŸ”")

        # ×¡×¤×™×¨×” ×©×œ ×¡×•×’×™ ×”×”×ª×××•×ª
        gray_zone_count = sum(1 for face, sim in potential_matches if sim < FIRST_THRESHOLD)
        first_pass_only_count = len(potential_matches) - gray_zone_count

        if gray_zone_count:
            print_status(f"- {gray_zone_count} ×¤× ×™× ×§×¨×•×‘×•×ª ×œ×¡×£ ×”×–×™×”×•×™", level=1)
        if first_pass_only_count:
            print_status(f"- {first_pass_only_count} ×¤× ×™× ×©×¢×‘×¨×• ×¨×§ ××ª ×”×‘×“×™×§×” ×”×¨××©×•× ×”", level=1)

        # ××™×•×Ÿ ×œ×¤×™ ×“××™×•×Ÿ ×™×•×¨×“ (×”×’×‘×•×” ×‘×™×•×ª×¨ ×¨××©×•×Ÿ)
        potential_matches.sort(key=lambda x: x[1], reverse=True)

        # ×”×’×“×¨×ª ×¡×£ ×œ×‘×“×™×§×” ×”××¢××™×§×”
        ENHANCED_VERIFICATION_THRESHOLD = 0.35

        matched_faces = []

        for face_in_db, similarity in potential_matches:
            # ×‘×“×™×§×” ××¢××™×§×” ×¢× ××¨×‘×¢ ×’×™×©×•×ª ×©×•× ×•×ª
            enhanced_similarity = self.perform_enhanced_verification(personal_image_path, face_in_db)

            if enhanced_similarity >= ENHANCED_VERIFICATION_THRESHOLD:
                print_status(
                    f"×‘×‘×“×™×§×” ××¢××™×§×” × ××¦××” ×”×ª×××” ×œ×ª××•× ×” {os.path.basename(face_in_db)} ({enhanced_similarity:.2%})",
                    level=1, emoji="âœ…")
                matched_faces.append(face_in_db)
            else:
                print_status(
                    f"×‘×‘×“×™×§×” ××¢××™×§×” ×œ× × ××¦××” ×”×ª×××” ××¡×¤×§×ª ×œ×ª××•× ×” {os.path.basename(face_in_db)} ({enhanced_similarity:.2%})",
                    level=1, emoji="âŒ")

        return matched_faces

# ==================================================================================
        """×‘×“×™×§×ª ×”×ª×××” ×‘×™×Ÿ ×ª××•× ×” ××™×©×™×ª ×œ×××’×¨ ×”×¤× ×™× - ×’×¨×¡×” ×¢× ×˜×¢×™× ×” ×—×›××”"""
# ==================================================================================
    def check_single_image(self, personal_image_path):
        try:
            # ×”×•×¡×£ ××©×ª× ×” ×©×™×¢×§×•×‘ ×× ×‘×•×¦×¢×” ×‘×“×™×§×” ××¢××™×§×”
            used_enhanced_verification = False

            faces_in_db = glob.glob(f"{self.enviro_faces_dir}/*.jpg")
            if not faces_in_db:
                print_status("×œ× × ××¦××• ×¤× ×™× ×‘×××’×¨", emoji="âŒ")
                return False

            if not os.path.exists(personal_image_path):
                print_status(f"×œ× × ××¦××” ×ª××•× ×” ××™×©×™×ª: {personal_image_path}", emoji="âŒ")
                return False

            parent_dir = os.path.basename(os.path.dirname(personal_image_path))
            identified_dir = "./Identified_Images"
            if not os.path.exists(identified_dir):
                os.makedirs(identified_dir)

            # ×”×’×“×¨×ª ××–×•×¨ ××¤×•×¨ - ×˜×•×•×— ×¢×¨×›×™× ×§×¨×•×‘×™× ×œ×¡×£ ×©×“×•×¨×©×™× ×‘×“×™×§×” × ×•×¡×¤×ª
            # GRAY_ZONE_FACTOR = 0.05  # 5% ××ª×—×ª ×œ×¡×£
            # GRAY_ZONE_THRESHOLD = FIRST_THRESHOLD - (FIRST_THRESHOLD * GRAY_ZONE_FACTOR)

            GRAY_ZONE_LOWER_THRESHOLD = 0.42  # ×”×¡×£ ×”×ª×—×ª×•×Ÿ ×©×œ ×”××–×•×¨ ×”××¤×•×¨ - 42%

            found_match = False
            results = []  # ×¨×©×™××” ×œ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×”×¦×’×ª×Ÿ ×‘×˜×‘×œ×”
            definite_matches = []  # ×”×ª×××•×ª ×•×“××™×•×ª (××¢×œ ×”×¡×£)
            gray_zone_matches = []  # ×”×ª×××•×ª ×‘××–×•×¨ ×”××¤×•×¨
            first_pass_only_matches = []  # ×—×“×©: ×”×ª×××•×ª ×©×¢×‘×¨×• ×¨×§ ××ª ×”×‘×“×™×§×” ×”×¨××©×•× ×”

            # ×˜×¢×™× ×ª ×”×ª××•× ×” ×”××™×©×™×ª ×¤×¢× ××—×ª
            personal_img = cv2.imread(personal_image_path)
            if personal_img is None:
                print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×”×ª××•× ×” ×”××™×©×™×ª: {personal_image_path}", emoji="âŒ")
                return False

            print_status(f"×‘×•×“×§ ×”×ª×××” ××•×œ {len(faces_in_db)} ×ª××•× ×•×ª ×‘×××’×¨", emoji="ğŸ”")

            # ×˜×¢×™× ×ª ×ª××•× ×•×ª ×”×××’×¨ ××¨××© ×œ×–×™×›×¨×•×Ÿ - ×—×•×¡×š ×˜×¢×™× ×•×ª ×—×•×–×¨×•×ª
            print_status("×˜×•×¢×Ÿ ×ª××•× ×•×ª ×××’×¨ ×œ×–×™×›×¨×•×Ÿ...", level=1)
            loaded_faces = {}
            for face_path in faces_in_db:
                face_img = cv2.imread(face_path)
                if face_img is not None:
                    loaded_faces[face_path] = face_img
                else:
                    print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ×ª××•× ×”: {os.path.basename(face_path)}", level=1, emoji="âš ï¸")

            print_status(f"× ×˜×¢× ×• {len(loaded_faces)} ×ª××•× ×•×ª ××ª×•×š {len(faces_in_db)}", level=1)

            # ×‘×“×™×§×” ×¨××©×•× ×” ×¢× Facenet512
            for face_in_db in faces_in_db:
                face_filename = os.path.basename(face_in_db)

                # ×ª××™×“ ×œ×”×¤×¢×™×œ ××ª ×©× ×™ ×”××•×“×œ×™×
                first_similarity = self.verify_face(personal_image_path, face_in_db)
                second_similarity = self.verify_face_second(personal_image_path, face_in_db)

                # ×—×™×©×•×‘ ×“××™×•×Ÿ ××©×•×œ×‘ (×œ×©×™××•×© ×¢×ª×™×“×™ ×‘-ROC)
                combined_similarity = (first_similarity + second_similarity) / 2

                # ×”××©×š ×”×œ×•×’×™×§×” ×”××§×•×¨×™×ª
                if first_similarity >= FIRST_THRESHOLD:
                    final_similarity = max(first_similarity, second_similarity)

                    # ××§×¨×” 1: ×¢×‘×¨ ×’× ××ª ×”×‘×“×™×§×” ×”×©× ×™×™×”
                    if second_similarity >= SECOND_THRESHOLD:
                        status_icon = "âœ…"
                        definite_matches.append(face_in_db)
                        found_match = True
                    # ××§×¨×” 2: ×¢×‘×¨ ×¨×§ ××ª ×”×‘×“×™×§×” ×”×¨××©×•× ×”
                    else:
                        status_icon = "â„¹ï¸"
                        first_pass_only_matches.append((face_in_db, first_similarity))

                # ××§×¨×” 3: ×‘××–×•×¨ ×”××¤×•×¨, ×§×¨×•×‘ ×××•×“ ×œ×¡×£
                elif first_similarity >= GRAY_ZONE_LOWER_THRESHOLD:
                    status_icon = "ğŸ”"
                    gray_zone_matches.append((face_in_db, first_similarity))
                    final_similarity = first_similarity
                # ××§×¨×” 4: ××ª×—×ª ×œ×¡×£
                else:
                    status_icon = "âŒ"
                    final_similarity = first_similarity

                # ×”×•×¡×£ ××ª ×”× ×ª×•× ×™× ×œ×¨×©×™××ª ×”×ª×•×¦××•×ª ×‘×¦×•×¨×ª ×¦×™×•×Ÿ ×“××™×•×Ÿ
                results.append([
                    os.path.basename(personal_image_path),  # ×ª××•× ×” × ×‘×“×§×ª
                    face_filename,  # ×ª××•× ×” ×‘×‘×¡×™×¡ ×”× ×ª×•× ×™×
                    f"{self.normalize_similarity_score(first_similarity):.2f}",  # ×“××™×•×Ÿ ×¨××©×•× ×™
                    f"{self.normalize_similarity_score(second_similarity):.2f}",  # ×“××™×•×Ÿ ××©× ×™
                    f"{self.normalize_similarity_score(final_similarity):.2f}",  # ×¦×™×•×Ÿ ×“××™×•×Ÿ ×¡×•×¤×™
                    status_icon  # ×¡×˜×˜×•×¡
                ])

            # ×”×“×¤×¡×ª ×›×œ ×”×ª×•×¦××•×ª ×‘×¦×•×¨×” ××¡×•×“×¨×ª ×‘×˜×‘×œ×” ××—×ª
            headers = ["×¡×˜×˜×•×¡", "×”×ª×××” ×¡×•×¤×™×ª", "×”×ª×××” ×©× ×™×™×”", "×”×ª×××” ×¨××©×•× ×”", "×ª××•× ×” ×‘×‘×¡×™×¡ ×”× ×ª×•× ×™×", "×ª××•× ×” × ×‘×“×§×ª"]
            print("\n" + tabulate(results, headers=headers, tablefmt="grid", stralign="center"))

            # ×× ×œ× × ××¦××• ×”×ª×××•×ª ×•×“××™×•×ª ××‘×œ ×™×© ×”×ª×××•×ª ×‘××–×•×¨ ×”××¤×•×¨ ××• ×©×¢×‘×¨×• ×¨×§ ×‘×“×™×§×” ×¨××©×•× ×”
            if not found_match and (gray_zone_matches or first_pass_only_matches):
                all_potential_matches = gray_zone_matches + first_pass_only_matches

                # ×¡×™××•×Ÿ ×©××ª×‘×¦×¢×ª ×‘×“×™×§×” ××¢××™×§×”
                used_enhanced_verification = True

                # ×”×¨×¦×ª ×”×‘×“×™×§×” ×”××¢××™×§×” ×‘×××¦×¢×•×ª ×”×¤×•× ×§×¦×™×” ×”×—×“×©×”
                deep_matched_faces = self.perform_deep_analysis(personal_image_path, all_potential_matches)

                # ×”×•×¡×¤×ª ×”×ª×•×¦××•×ª ×”××•×¦×œ×—×•×ª ×œ×¨×©×™××ª ×”×”×ª×××•×ª ×”×¡×•×¤×™×ª
                if deep_matched_faces:
                    definite_matches.extend(deep_matched_faces)
                    found_match = True

            if found_match:
                print_status(f"× ××¦××• {len(definite_matches)} ×¤× ×™× ××ª××™××•×ª, ×‘×•×“×§ ×”×ª×××ª ××‘× ×” ×¤× ×™×...", emoji="ğŸ”")

                # ×‘×“×™×§×” ×× ×›×‘×¨ ×‘×•×¦×¢×” ×‘×“×™×§×” ××¢××™×§×” ×©×›×•×œ×œ×ª ××ª ×‘×“×™×§×ª × ×§×•×“×•×ª ×”×¦×™×•×Ÿ
                if used_enhanced_verification:
                    print_status(f"×“×™×œ×•×’ ×¢×œ ×‘×“×™×§×ª ××‘× ×” ×¤× ×™× × ×•×¡×¤×ª - ×›×‘×¨ ×‘×•×¦×¢×” ×‘×“×™×§×” ××¢××™×§×”", level=1, emoji="â†ªï¸")
                else:
                    # × ×‘×“×•×§ ××ª ×™×—×¡ ×”×¨×•×—×‘ ×‘×›×œ ×”×”×ª×××•×ª ×©× ××¦××•
                    matches_to_remove = []
                    for face_in_db in definite_matches:
                        # ×”×©×ª××© ×‘×ª××•× ×•×ª ×©×›×‘×¨ × ×˜×¢× ×• ×œ×–×™×›×¨×•×Ÿ
                        db_img = loaded_faces.get(face_in_db)

                        # ×× ×”×ª××•× ×” ×œ× × ×˜×¢× ×” ×‘×”×¦×œ×—×”, × × ×¡×” ×œ×˜×¢×•×Ÿ ×©×•×‘
                        if db_img is None:
                            db_img = cv2.imread(face_in_db)
                            if db_img is None:
                                print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ×ª××•× ×”: {os.path.basename(face_in_db)}", level=1,
                                             emoji="âš ï¸")
                                matches_to_remove.append(face_in_db)
                                continue

                        # ×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ ×¤× ×™×
                        width_check_result = self.check_face_width_ratio(personal_img, db_img, personal_image_path,
                                                                         face_in_db)

                        if width_check_result == "NO_FACE_DETECTED":
                            # ×× ×œ× ×–×•×”×• ×¤× ×™×, ×××©×™×›×™× ×•×œ× ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                            print_status(f"×××©×™×š ×¢× ×”×ª××•× ×” ×œ××¨×•×ª ×›×©×œ ×‘×–×™×”×•×™ ××‘× ×”: {os.path.basename(face_in_db)}",
                                         level=1, emoji="â¡ï¸")
                        elif width_check_result == "ERROR":
                            # ×× ×”×™×™×ª×” ×©×’×™××”, ×××©×™×›×™× ×•×œ× ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                            print_status(f"×××©×™×š ×¢× ×”×ª××•× ×” ×œ××¨×•×ª ×©×’×™××” ×‘×‘×“×™×§×ª ××‘× ×”: {os.path.basename(face_in_db)}",
                                         level=1, emoji="â¡ï¸")
                        elif width_check_result == False:
                            # ×¨×§ ×× ×–×•×”×• ×¤× ×™× ×•× ××¦× ×©×”×Ÿ ×œ× ××ª××™××•×ª, ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                            print_status(f"×”×ª×××” × ×“×—×ª×” ×¢×§×‘ ×”×‘×“×œ ××©××¢×•×ª×™ ×‘××‘× ×” ×”×¤× ×™×: {os.path.basename(face_in_db)}",
                                         level=1, emoji="â›”")
                            matches_to_remove.append(face_in_db)

                    # ×”×¡×¨×ª ×”×”×ª×××•×ª ×©× ×›×©×œ×• ×‘×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ
                    for face_to_remove in matches_to_remove:
                        definite_matches.remove(face_to_remove)

                # ×”××©×š ×¨×§ ×× × ×©××¨×• ×”×ª×××•×ª ×œ××—×¨ ×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ
                if definite_matches:
                    # ×”××©×š ×”×§×•×“ ×”×§×™×™× ×œ×”×¢×ª×§×ª ×”×”×ª×××•×ª
                    for face_in_db in definite_matches:
                        try:
                            # ×”×¢×ª×§×ª ×”×ª××•× ×” ×”××–×•×”×” ×œ-Identified_Images
                            original_number = os.path.basename(face_in_db).split('_')[-1].split('.')[0]
                            new_filename = f"{parent_dir}_{original_number}.jpg"
                            new_path = os.path.join(identified_dir, new_filename)

                            shutil.copy2(face_in_db, new_path)
                            print_status(f"×”×¤× ×™× ×”××ª××™××•×ª ×”×•×¢×ª×§×• ×œ: {new_filename}", level=1, emoji="ğŸ“‹")
                        except Exception as file_error:
                            print_status(f"×©×’×™××” ×‘×˜×™×¤×•×œ ×‘×§×‘×¦×™×: {str(file_error)}", level=1, emoji="âš ï¸")
                else:
                    print_status("×œ× × ×©××¨×• ×”×ª×××•×ª ×œ××—×¨ ×‘×“×™×§×ª ××‘× ×” ×¤× ×™×", emoji="â“")
                    found_match = False
            else:
                print_status("×œ× × ××¦××” ×”×ª×××” ×‘×××’×¨", emoji="â“")

            # × ×™×§×•×™ ×–×™×›×¨×•×Ÿ
            loaded_faces.clear()

            return found_match

        except Exception as e:
            print_status(f"×©×’×™××” ×‘×‘×“×™×§×ª ×ª××•× ×” ×‘×•×“×“×ª: {str(e)}", emoji="âŒ")
            return False

# ==================================================================================
            "××§×‘×œ×ª URL ×©×œ ×ª××•× ×” ××™×©×™×ª ×•×‘×•×“×§×ª ××•×ª×” ××•×œ ×ª×™×§×™×™×ª EnviroFaces ×”××§×•××™×ª"
# ==================================================================================
    def check_person_against_environment(self, personal_image_url):

        try:
            # 'with' × ××¦× ×¨××” ××—×ª ×¤× ×™××” ××”-def, ×•×–×” × ×›×•×Ÿ
            with temp_image_from_url(personal_image_url) as personal_image_path:

                # ×›×œ ×”×§×•×“ ×”×‘× ××•×–×— ×¨××” ××—×ª × ×•×¡×¤×ª ×¤× ×™××”, ×ª×—×ª ×”-'with'
                faces_in_db = glob.glob(f"{self.enviro_faces_dir}/*.jpg")
                if not faces_in_db:
                    print_status("×œ× × ××¦××• ×¤× ×™× ×‘×××’×¨ ×”×–×× ×™ (EnviroFaces)", emoji="âŒ")
                    return False

                if not os.path.exists(personal_image_path):
                    print_status(f"×©×’×™××”: ×œ× × ×•×¦×¨ ×§×•×‘×¥ ×–×× ×™ ×¢×‘×•×¨ ×”×ª××•× ×” ×”××™×©×™×ª", emoji="âŒ")
                    return False

                used_enhanced_verification = False

                faces_in_db = glob.glob(f"{self.enviro_faces_dir}/*.jpg")
                if not faces_in_db:
                    print_status("×œ× × ××¦××• ×¤× ×™× ×‘×××’×¨", emoji="âŒ")
                    return False

                if not os.path.exists(personal_image_path):
                    print_status(f"×œ× × ××¦××” ×ª××•× ×” ××™×©×™×ª: {personal_image_path}", emoji="âŒ")
                    return False

                parent_dir = os.path.basename(os.path.dirname(personal_image_path))
                identified_dir = "./Identified_Images"
                if not os.path.exists(identified_dir):
                    os.makedirs(identified_dir)

                # ×”×’×“×¨×ª ××–×•×¨ ××¤×•×¨ - ×˜×•×•×— ×¢×¨×›×™× ×§×¨×•×‘×™× ×œ×¡×£ ×©×“×•×¨×©×™× ×‘×“×™×§×” × ×•×¡×¤×ª
                # GRAY_ZONE_FACTOR = 0.05  # 5% ××ª×—×ª ×œ×¡×£
                # GRAY_ZONE_THRESHOLD = FIRST_THRESHOLD - (FIRST_THRESHOLD * GRAY_ZONE_FACTOR)

                GRAY_ZONE_LOWER_THRESHOLD = 0.42  # ×”×¡×£ ×”×ª×—×ª×•×Ÿ ×©×œ ×”××–×•×¨ ×”××¤×•×¨ - 42%

                found_match = False
                results = []  # ×¨×©×™××” ×œ×©××™×¨×ª ×”×ª×•×¦××•×ª ×œ×”×¦×’×ª×Ÿ ×‘×˜×‘×œ×”
                definite_matches = []  # ×”×ª×××•×ª ×•×“××™×•×ª (××¢×œ ×”×¡×£)
                gray_zone_matches = []  # ×”×ª×××•×ª ×‘××–×•×¨ ×”××¤×•×¨
                first_pass_only_matches = []  # ×—×“×©: ×”×ª×××•×ª ×©×¢×‘×¨×• ×¨×§ ××ª ×”×‘×“×™×§×” ×”×¨××©×•× ×”

                # ×˜×¢×™× ×ª ×”×ª××•× ×” ×”××™×©×™×ª ×¤×¢× ××—×ª
                personal_img = cv2.imread(personal_image_path)
                if personal_img is None:
                    print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×”×ª××•× ×” ×”××™×©×™×ª: {personal_image_path}", emoji="âŒ")
                    return False

                print_status(f"×‘×•×“×§ ×”×ª×××” ××•×œ {len(faces_in_db)} ×ª××•× ×•×ª ×‘×××’×¨", emoji="ğŸ”")

                # ×˜×¢×™× ×ª ×ª××•× ×•×ª ×”×××’×¨ ××¨××© ×œ×–×™×›×¨×•×Ÿ - ×—×•×¡×š ×˜×¢×™× ×•×ª ×—×•×–×¨×•×ª
                print_status("×˜×•×¢×Ÿ ×ª××•× ×•×ª ×××’×¨ ×œ×–×™×›×¨×•×Ÿ...", level=1)
                loaded_faces = {}
                for face_path in faces_in_db:
                    face_img = cv2.imread(face_path)
                    if face_img is not None:
                        loaded_faces[face_path] = face_img
                    else:
                        print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ×ª××•× ×”: {os.path.basename(face_path)}", level=1, emoji="âš ï¸")

                print_status(f"× ×˜×¢× ×• {len(loaded_faces)} ×ª××•× ×•×ª ××ª×•×š {len(faces_in_db)}", level=1)

                # ×‘×“×™×§×” ×¨××©×•× ×” ×¢× Facenet512
                for face_in_db in faces_in_db:
                    face_filename = os.path.basename(face_in_db)

                    # ×ª××™×“ ×œ×”×¤×¢×™×œ ××ª ×©× ×™ ×”××•×“×œ×™×
                    first_similarity = self.verify_face(personal_image_path, face_in_db)
                    second_similarity = self.verify_face_second(personal_image_path, face_in_db)

                    # ×—×™×©×•×‘ ×“××™×•×Ÿ ××©×•×œ×‘ (×œ×©×™××•×© ×¢×ª×™×“×™ ×‘-ROC)
                    combined_similarity = (first_similarity + second_similarity) / 2

                    # ×”××©×š ×”×œ×•×’×™×§×” ×”××§×•×¨×™×ª
                    if first_similarity >= FIRST_THRESHOLD:
                        final_similarity = max(first_similarity, second_similarity)

                        # ××§×¨×” 1: ×¢×‘×¨ ×’× ××ª ×”×‘×“×™×§×” ×”×©× ×™×™×”
                        if second_similarity >= SECOND_THRESHOLD:
                            status_icon = "âœ…"
                            definite_matches.append(face_in_db)
                            found_match = True
                        # ××§×¨×” 2: ×¢×‘×¨ ×¨×§ ××ª ×”×‘×“×™×§×” ×”×¨××©×•× ×”
                        else:
                            status_icon = "â„¹ï¸"
                            first_pass_only_matches.append((face_in_db, first_similarity))

                    # ××§×¨×” 3: ×‘××–×•×¨ ×”××¤×•×¨, ×§×¨×•×‘ ×××•×“ ×œ×¡×£
                    elif first_similarity >= GRAY_ZONE_LOWER_THRESHOLD:
                        status_icon = "ğŸ”"
                        gray_zone_matches.append((face_in_db, first_similarity))
                        final_similarity = first_similarity
                    # ××§×¨×” 4: ××ª×—×ª ×œ×¡×£
                    else:
                        status_icon = "âŒ"
                        final_similarity = first_similarity

                    # ×”×•×¡×£ ××ª ×”× ×ª×•× ×™× ×œ×¨×©×™××ª ×”×ª×•×¦××•×ª ×‘×¦×•×¨×ª ×¦×™×•×Ÿ ×“××™×•×Ÿ
                    results.append([
                        os.path.basename(personal_image_path),  # ×ª××•× ×” × ×‘×“×§×ª
                        face_filename,  # ×ª××•× ×” ×‘×‘×¡×™×¡ ×”× ×ª×•× ×™×
                        f"{self.normalize_similarity_score(first_similarity):.2f}",  # ×“××™×•×Ÿ ×¨××©×•× ×™
                        f"{self.normalize_similarity_score(second_similarity):.2f}",  # ×“××™×•×Ÿ ××©× ×™
                        f"{self.normalize_similarity_score(final_similarity):.2f}",  # ×¦×™×•×Ÿ ×“××™×•×Ÿ ×¡×•×¤×™
                        status_icon  # ×¡×˜×˜×•×¡
                    ])

                # ×”×“×¤×¡×ª ×›×œ ×”×ª×•×¦××•×ª ×‘×¦×•×¨×” ××¡×•×“×¨×ª ×‘×˜×‘×œ×” ××—×ª
                headers = ["×¡×˜×˜×•×¡", "×”×ª×××” ×¡×•×¤×™×ª", "×”×ª×××” ×©× ×™×™×”", "×”×ª×××” ×¨××©×•× ×”", "×ª××•× ×” ×‘×‘×¡×™×¡ ×”× ×ª×•× ×™×", "×ª××•× ×” × ×‘×“×§×ª"]
                print("\n" + tabulate(results, headers=headers, tablefmt="grid", stralign="center"))

                # ×× ×œ× × ××¦××• ×”×ª×××•×ª ×•×“××™×•×ª ××‘×œ ×™×© ×”×ª×××•×ª ×‘××–×•×¨ ×”××¤×•×¨ ××• ×©×¢×‘×¨×• ×¨×§ ×‘×“×™×§×” ×¨××©×•× ×”
                if not found_match and (gray_zone_matches or first_pass_only_matches):
                    all_potential_matches = gray_zone_matches + first_pass_only_matches

                    # ×¡×™××•×Ÿ ×©××ª×‘×¦×¢×ª ×‘×“×™×§×” ××¢××™×§×”
                    used_enhanced_verification = True

                    # ×”×¨×¦×ª ×”×‘×“×™×§×” ×”××¢××™×§×” ×‘×××¦×¢×•×ª ×”×¤×•× ×§×¦×™×” ×”×—×“×©×”
                    deep_matched_faces = self.perform_deep_analysis(personal_image_path, all_potential_matches)

                    # ×”×•×¡×¤×ª ×”×ª×•×¦××•×ª ×”××•×¦×œ×—×•×ª ×œ×¨×©×™××ª ×”×”×ª×××•×ª ×”×¡×•×¤×™×ª
                    if deep_matched_faces:
                        definite_matches.extend(deep_matched_faces)
                        found_match = True

                if found_match:
                    print_status(f"× ××¦××• {len(definite_matches)} ×¤× ×™× ××ª××™××•×ª, ×‘×•×“×§ ×”×ª×××ª ××‘× ×” ×¤× ×™×...", emoji="ğŸ”")

                    # ×‘×“×™×§×” ×× ×›×‘×¨ ×‘×•×¦×¢×” ×‘×“×™×§×” ××¢××™×§×” ×©×›×•×œ×œ×ª ××ª ×‘×“×™×§×ª × ×§×•×“×•×ª ×”×¦×™×•×Ÿ
                    if used_enhanced_verification:
                        print_status(f"×“×™×œ×•×’ ×¢×œ ×‘×“×™×§×ª ××‘× ×” ×¤× ×™× × ×•×¡×¤×ª - ×›×‘×¨ ×‘×•×¦×¢×” ×‘×“×™×§×” ××¢××™×§×”", level=1, emoji="â†ªï¸")
                    else:
                        # × ×‘×“×•×§ ××ª ×™×—×¡ ×”×¨×•×—×‘ ×‘×›×œ ×”×”×ª×××•×ª ×©× ××¦××•
                        matches_to_remove = []
                        for face_in_db in definite_matches:
                            # ×”×©×ª××© ×‘×ª××•× ×•×ª ×©×›×‘×¨ × ×˜×¢× ×• ×œ×–×™×›×¨×•×Ÿ
                            db_img = loaded_faces.get(face_in_db)

                            # ×× ×”×ª××•× ×” ×œ× × ×˜×¢× ×” ×‘×”×¦×œ×—×”, × × ×¡×” ×œ×˜×¢×•×Ÿ ×©×•×‘
                            if db_img is None:
                                db_img = cv2.imread(face_in_db)
                                if db_img is None:
                                    print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ×ª××•× ×”: {os.path.basename(face_in_db)}", level=1,
                                                 emoji="âš ï¸")
                                    matches_to_remove.append(face_in_db)
                                    continue

                            # ×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ ×¤× ×™×
                            width_check_result = self.check_face_width_ratio(personal_img, db_img, personal_image_path,
                                                                             face_in_db)

                            if width_check_result == "NO_FACE_DETECTED":
                                # ×× ×œ× ×–×•×”×• ×¤× ×™×, ×××©×™×›×™× ×•×œ× ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                                print_status(f"×××©×™×š ×¢× ×”×ª××•× ×” ×œ××¨×•×ª ×›×©×œ ×‘×–×™×”×•×™ ××‘× ×”: {os.path.basename(face_in_db)}",
                                             level=1, emoji="â¡ï¸")
                            elif width_check_result == "ERROR":
                                # ×× ×”×™×™×ª×” ×©×’×™××”, ×××©×™×›×™× ×•×œ× ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                                print_status(f"×××©×™×š ×¢× ×”×ª××•× ×” ×œ××¨×•×ª ×©×’×™××” ×‘×‘×“×™×§×ª ××‘× ×”: {os.path.basename(face_in_db)}",
                                             level=1, emoji="â¡ï¸")
                            elif width_check_result == False:
                                # ×¨×§ ×× ×–×•×”×• ×¤× ×™× ×•× ××¦× ×©×”×Ÿ ×œ× ××ª××™××•×ª, ××¡×™×¨×™× ××ª ×”×ª××•× ×”
                                print_status(
                                    f"×”×ª×××” × ×“×—×ª×” ×¢×§×‘ ×”×‘×“×œ ××©××¢×•×ª×™ ×‘××‘× ×” ×”×¤× ×™×: {os.path.basename(face_in_db)}",
                                    level=1, emoji="â›”")
                                matches_to_remove.append(face_in_db)

                        # ×”×¡×¨×ª ×”×”×ª×××•×ª ×©× ×›×©×œ×• ×‘×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ
                        for face_to_remove in matches_to_remove:
                            definite_matches.remove(face_to_remove)

                    # ×”××©×š ×¨×§ ×× × ×©××¨×• ×”×ª×××•×ª ×œ××—×¨ ×‘×“×™×§×ª × ×§×•×“×•×ª ×¦×™×•×Ÿ
                    if definite_matches:
                        # ×”××©×š ×”×§×•×“ ×”×§×™×™× ×œ×”×¢×ª×§×ª ×”×”×ª×××•×ª
                        for face_in_db in definite_matches:
                            try:
                                # ×”×¢×ª×§×ª ×”×ª××•× ×” ×”××–×•×”×” ×œ-Identified_Images
                                original_number = os.path.basename(face_in_db).split('_')[-1].split('.')[0]
                                new_filename = f"{parent_dir}_{original_number}.jpg"
                                new_path = os.path.join(identified_dir, new_filename)

                                shutil.copy2(face_in_db, new_path)
                                print_status(f"×”×¤× ×™× ×”××ª××™××•×ª ×”×•×¢×ª×§×• ×œ: {new_filename}", level=1, emoji="ğŸ“‹")
                            except Exception as file_error:
                                print_status(f"×©×’×™××” ×‘×˜×™×¤×•×œ ×‘×§×‘×¦×™×: {str(file_error)}", level=1, emoji="âš ï¸")
                    else:
                        print_status("×œ× × ×©××¨×• ×”×ª×××•×ª ×œ××—×¨ ×‘×“×™×§×ª ××‘× ×” ×¤× ×™×", emoji="â“")
                        found_match = False
                else:
                    print_status("×œ× × ××¦××” ×”×ª×××” ×‘×××’×¨", emoji="â“")

                # × ×™×§×•×™ ×–×™×›×¨×•×Ÿ
                loaded_faces.clear()

                return found_match

            # ×”-except × ××¦× ×‘××•×ª×” ×¨××” ×›××• ×”-try
        except Exception as e:
            print_status(f"×©×’×™××” ×‘×‘×“×™×§×ª ×ª××•× ×” ×-URL: {str(e)}", emoji="âŒ")
            return False


# ==================================================================================
            "×‘×“×™×§×ª ×”×ª×××” ×‘×™×Ÿ ×ª××•× ×•×ª ×××•××ª×•×ª ×©×œ ××“× ×œ×ª××•× ×•×ª ×©×–×•×”×• ×›×©×œ×•"
# ==================================================================================
    def verify_person_images(self, person_details):

        try:
            first_name, last_name, id_number = person_details.split()
            person_id = f"{first_name}_{last_name}_{id_number}"

            print_status(f"×‘×•×“×§ ×ª××•× ×•×ª ×©×œ {first_name} {last_name}", emoji="ğŸ‘¤")

            verified_dir = f"./{person_id}"
            if not os.path.exists(verified_dir):
                print_status(f"×œ× × ××¦××” ×ª×™×§×™×™×ª ×ª××•× ×•×ª ×××•××ª×•×ª ×¢×‘×•×¨ {person_id}", level=1, emoji="âŒ")
                return {}

            verified_images = glob.glob(f"{verified_dir}/*.jpg")
            if not verified_images:
                print_status(f"×œ× × ××¦××• ×ª××•× ×•×ª ×××•××ª×•×ª ×‘×ª×™×§×™×™×” {verified_dir}", level=1, emoji="âŒ")
                return {}

            identified_pattern = f"./Identified_Images/{person_id}_*.jpg"
            identified_images = glob.glob(identified_pattern)
            if not identified_images:
                print_status(f"×œ× × ××¦××• ×ª××•× ×•×ª ××–×•×”×•×ª ×¢×‘×•×¨ {person_id}", level=1, emoji="âŒ")
                return {}

            print_status(f"× ××¦××• {len(verified_images)} ×ª××•× ×•×ª ×××•××ª×•×ª ×•-{len(identified_images)} ×ª××•× ×•×ª ××–×•×”×•×ª",
                         level=1, emoji="ğŸ“Š")

            results = {}

            for identified_img in identified_images:
                img_name = os.path.basename(identified_img)
                print_status(f"×‘×•×“×§ ×ª××•× ×” ××–×•×”×”: {img_name}", level=1, emoji="ğŸ”")

                img_results = {
                    'verified_matches': [],
                    'highest_similarity': 0,
                    'average_similarity': 0,
                    'passed_threshold': False
                }

                similarities = []

                for verified_img in verified_images:
                    verified_name = os.path.basename(verified_img)
                    first_check = self.verify_face(identified_img, verified_img)

                    if first_check >= FIRST_THRESHOLD:
                        second_check = self.verify_face_second(identified_img, verified_img)

                        if second_check >= SECOND_THRESHOLD:
                            similarity = (first_check + second_check) / 2
                            similarities.append(similarity)
                            img_results['verified_matches'].append({
                                'verified_image': os.path.basename(verified_img),
                                'similarity': similarity
                            })
                            print_status(f"×”×ª×××” ×¢× {verified_name}: {similarity:.2%}", level=2, emoji="âœ…")

                if similarities:
                    img_results['highest_similarity'] = max(similarities)
                    img_results['average_similarity'] = sum(similarities) / len(similarities)
                    img_results['passed_threshold'] = img_results['highest_similarity'] >= (
                            (FIRST_THRESHOLD + SECOND_THRESHOLD) / 2)

                    threshold_emoji = "âœ…" if img_results['passed_threshold'] else "âŒ"

                    print_status(f"×¡×™×›×•× ×¢×‘×•×¨ {img_name}:", level=2)
                    print_status(f"× ××¦××• {len(img_results['verified_matches'])} ×”×ª×××•×ª", level=3)
                    print_status(f"×¦×™×•×Ÿ ×“××™×•×Ÿ ××™×¨×‘×™: {self.normalize_similarity_score(img_results['highest_similarity']):.2f}", level=3)
                    print_status(f"×¦×™×•×Ÿ ×“××™×•×Ÿ ×××•×¦×¢: {self.normalize_similarity_score(img_results['average_similarity']):.2f}", level=3)
                    print_status(f"×¢×‘×¨ ×¡×£: {threshold_emoji}", level=3)
                else:
                    print_status(f"×œ× × ××¦××• ×”×ª×××•×ª ×œ×ª××•× ×” ×–×•", level=2, emoji="âŒ")

                results[os.path.basename(identified_img)] = img_results

            print_status(f"×”×•×©×œ××” ×‘×“×™×§×ª ×”×ª××•× ×•×ª ×©×œ {first_name} {last_name}", emoji="âœ…")
            return results

        except Exception as e:
            print_status(f"×©×’×™××” ×‘×‘×“×™×§×ª ×ª××•× ×•×ª ××“×: {str(e)}", emoji="âŒ")
            return {}