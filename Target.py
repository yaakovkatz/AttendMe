import os
import cv2
import numpy as np
from ultralytics import YOLO
import requests
from io import BytesIO
import cloudinary
import cloudinary.uploader
import cloudinary.api
from datetime import datetime


def print_status(message, emoji="â„¹ï¸", level=0):
    """×¤×•× ×§×¦×™×” ×œ×”×“×¤×¡×ª ×¡×˜×˜×•×¡ ×¢× ×¨××•×ª ×”×–×—×”"""
    indent = "  " * level
    print(f"{indent}{emoji} {message}")


class Target:
    def __init__(self, camera_number, images_url, yolo_model_path="yolov8n-face.pt",
                 enable_face_detection=False, school_id=None):
        # ××™×“×¢ ×‘×¡×™×¡×™
        self.camera_number = camera_number
        self.image_url = images_url
        self.school_id = school_id  # ×§×™×©×•×¨ ×œ×‘×™×ª ×¡×¤×¨

        # ××™×“×¢ × ×•×¡×£
        self.created_at = datetime.now()
        self.last_updated = datetime.now()
        self.camera_location = ""  # ××™×§×•× ×”××¦×œ××”
        self.camera_description = ""  # ×ª×™××•×¨ ×”××¦×œ××”

        # ×¡×˜×˜×•×¡
        self._is_checked = False
        self.is_active = True

        # × ×ª×•× ×™ ×¤× ×™×
        self.extracted_faces = []
        self.faces_count = 0
        self.yolo_model = None

        # ×¢×¨×›×™ ×¡×£ ×œ×‘×“×™×§×•×ª ××™×›×•×ª
        self.FACE_SIZE_THRESHOLD = 0.01  # 1% ××’×•×“×œ ×”×ª××•× ×”
        self.MIN_SHARPNESS = 100
        self.MAX_NOISE_THRESHOLD = 50
        self.MIN_CONTRAST = 30

        # ×¡×˜×˜×™×¡×˜×™×§×•×ª
        self.total_faces_detected = 0
        self.quality_faces_saved = 0
        self.last_detection_time = None

        print_status(f"âœ… × ×•×¦×¨×” ××˜×¨×” ×—×“×©×”: ××¦×œ××” {camera_number}")

        # ×˜×¢×™× ×ª ××•×“×œ YOLO ×¨×§ ×× × ×“×¨×© ×•×× ×”×§×•×‘×¥ ×§×™×™×
        if enable_face_detection:
            self.enable_face_detection_now(yolo_model_path)

    @property
    def is_checked(self):
        """getter ×œ×¡×˜×˜×•×¡ ×‘×“×™×§×”"""
        return self._is_checked

    @is_checked.setter
    def is_checked(self, value):
        """setter ×œ×¡×˜×˜×•×¡ ×‘×“×™×§×”"""
        self._is_checked = value
        if value:
            self.last_updated = datetime.now()

    @property
    def image_urls(self):
        """××—×–×™×¨ ×¨×©×™××ª URLs ×©×œ ×ª××•× ×•×ª (×ª××™××•×ª ×œ×§×•×“ ×”×§×™×™×)"""
        if isinstance(self.image_url, list):
            return self.image_url
        else:
            return [self.image_url] if self.image_url else []

    # --- ×¤×•× ×§×¦×™×•×ª ×—×“×©×•×ª ×œ× ×™×”×•×œ ---

    def set_camera_info(self, location="", description=""):
        """×§×‘×™×¢×ª ××™×“×¢ ×¢×œ ×”××¦×œ××”"""
        self.camera_location = location
        self.camera_description = description
        self.last_updated = datetime.now()
        print_status(f"âœ… ××™×“×¢ ××¦×œ××” ×¢×•×“×›×Ÿ: {self.camera_number}")

    def activate(self):
        """×”×¤×¢×œ×ª ×”××¦×œ××”"""
        self.is_active = True
        self.last_updated = datetime.now()
        print_status(f"âœ… ××¦×œ××” {self.camera_number} ×”×•×¤×¢×œ×”")

    def deactivate(self):
        """×”×©×‘×ª×ª ×”××¦×œ××”"""
        self.is_active = False
        self.last_updated = datetime.now()
        print_status(f"âš ï¸ ××¦×œ××” {self.camera_number} ×”×•×©×‘×ª×”")

    def get_target_summary(self):
        """×§×‘×œ×ª ×¡×™×›×•× ×”××˜×¨×”"""
        return {
            "camera_number": self.camera_number,
            "school_id": self.school_id,
            "location": self.camera_location,
            "description": self.camera_description,
            "is_active": self.is_active,
            "faces_count": self.faces_count,
            "quality_faces": self.quality_faces_saved,
            "last_updated": self.last_updated.strftime("%d/%m/%Y %H:%M")
        }

    def get_target_details(self):
        """×§×‘×œ×ª ×¤×¨×˜×™ ×”××˜×¨×” ×”××œ××™×"""
        return {
            "basic_info": {
                "camera_number": self.camera_number,
                "school_id": self.school_id,
                "camera_location": self.camera_location,
                "camera_description": self.camera_description,
                "is_active": self.is_active
            },
            "images": {
                "image_url": self.image_url,
                "image_urls": self.image_urls
            },
            "face_detection": {
                "faces_count": self.faces_count,
                "extracted_faces": self.extracted_faces,
                "total_detected": self.total_faces_detected,
                "quality_saved": self.quality_faces_saved,
                "model_loaded": self.yolo_model is not None
            },
            "timestamps": {
                "created_at": self.created_at.isoformat(),
                "last_updated": self.last_updated.isoformat(),
                "last_detection": self.last_detection_time.isoformat() if self.last_detection_time else None
            },
            "status": {
                "is_checked": self.is_checked
            }
        }

    # --- ×¤×•× ×§×¦×™×•×ª ×‘×“×™×§×ª ××™×›×•×ª ×§×™×™××•×ª ---

    def check_face_size(self, face_area, image_area):
        """×‘×“×™×§×ª ×’×•×“×œ ×”×¤× ×™× ×‘×™×—×¡ ×œ×ª××•× ×”"""
        if image_area == 0:
            return False, 0

        face_ratio = face_area / image_area
        is_big_enough = face_ratio >= self.FACE_SIZE_THRESHOLD
        return is_big_enough, face_ratio

    def check_face_sharpness(self, face_image):
        """×‘×“×™×§×ª ×—×“×•×ª ×”×¤× ×™× ×‘×ª××•× ×”"""
        if face_image is None or face_image.size == 0:
            return False, 0

        gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        is_sharp = sharpness >= self.MIN_SHARPNESS
        return is_sharp, sharpness

    def check_face_noise(self, face_image):
        """×‘×“×™×§×ª ×¨××ª ×”×¨×¢×© ×‘×ª××•× ×ª ×”×¤× ×™×"""
        if face_image is None or face_image.size == 0:
            return False, 0

        gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
        noise = cv2.meanStdDev(gray)[1][0][0]
        is_clean = noise <= self.MAX_NOISE_THRESHOLD
        return is_clean, noise

    def check_face_contrast(self, face_image):
        """×‘×“×™×§×ª × ×™×’×•×“×™×•×ª ×‘×ª××•× ×ª ×”×¤× ×™×"""
        if face_image is None or face_image.size == 0:
            return False, 0

        gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
        min_val, max_val = np.min(gray), np.max(gray)

        # ×× ×™×¢×ª ×—×œ×•×§×” ×‘××¤×¡
        if max_val + min_val == 0:
            return False, 0

        contrast = max_val - min_val
        has_good_contrast = contrast >= self.MIN_CONTRAST
        return has_good_contrast, contrast

    # --- ×¤×•× ×§×¦×™×•×ª ×—×™×œ×•×¥ ×¤× ×™× ××¢×•×“×›× ×•×ª ---

    def enable_face_detection_now(self, yolo_model_path="yolov8n-face.pt"):
        """×”×¤×¢×œ×ª ×–×™×”×•×™ ×¤× ×™×"""
        try:
            if os.path.exists(yolo_model_path):
                self.yolo_model = YOLO(yolo_model_path)
                print_status(f"âœ… ××•×“×œ YOLO × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”: {yolo_model_path}")
                return True
            else:
                print_status(f"âŒ ×§×•×‘×¥ ××•×“×œ YOLO ×œ× × ××¦×: {yolo_model_path}")
                return False
        except Exception as e:
            print_status(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ××•×“×œ YOLO: {str(e)}")
            return False

    def extract_faces(self):
        """
        ××—×œ×¦×ª ×¤× ×™× ××ª××•× ×•×ª ×‘-Cloudinary ×•××¢×œ×” ××•×ª× ×—×–×¨×”
        ×’×¨×¡×” ××¢×•×“×›× ×ª ×¢× ×¡×˜×˜×™×¡×˜×™×§×•×ª ×•×§×™×©×•×¨ ×œ×‘×™×ª ×¡×¤×¨
        """
        # ×‘×“×™×§×” ×©××•×“×œ YOLO ×–××™×Ÿ
        if self.yolo_model is None:
            print_status("âš ï¸ ××•×“×œ YOLO ×œ× ×–××™×Ÿ, ××“×œ×’ ×¢×œ ×—×™×œ×•×¥ ×¤× ×™×")
            return 0

        if not self.is_active:
            print_status(f"âš ï¸ ××¦×œ××” {self.camera_number} ×œ× ×¤×¢×™×œ×”, ××“×œ×’ ×¢×œ ×—×™×œ×•×¥ ×¤× ×™×")
            return 0

        try:
            print_status(f"ğŸ” ×”×ª×—×œ×ª ×¡×¨×™×§×ª ×ª××•× ×”: ××¦×œ××” {self.camera_number}", emoji="â˜ï¸")

            # ××™×¤×•×¡ ××©×ª× ×™×
            self.extracted_faces = []
            old_faces_count = self.faces_count
            self.faces_count = 0

            # ×× ×–×” URL ×™×©×™×¨ ×©×œ ×ª××•× ×”
            if isinstance(self.image_url, str) and (
                    self.image_url.startswith('http') or self.image_url.startswith('https')):
                try:
                    print_status(f"××¢×‘×“ ×ª××•× ×”: {self.image_url}", level=1)

                    # ×”×•×¨×“×ª ×”×ª××•× ×” ×-URL
                    response = requests.get(self.image_url, timeout=15)
                    if response.status_code != 200:
                        print_status(f"×œ× × ×™×ª×Ÿ ×œ×”×•×¨×™×“ ××ª ×”×ª××•× ×” (×§×•×“: {response.status_code})", level=1, emoji="âŒ")
                        return 0

                    # ×”××¨×” ×œ-OpenCV format
                    image_bytes = BytesIO(response.content)
                    image_array = np.frombuffer(image_bytes.getvalue(), np.uint8)
                    img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)

                    if img is None:
                        print_status(f"×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª ×”×ª××•× ×”", level=1, emoji="âŒ")
                        return 0

                    # ×–×™×”×•×™ ×¤× ×™×
                    image_area = img.shape[0] * img.shape[1]
                    print_status(f"××ª×—×™×œ ×–×™×”×•×™ ×¤× ×™× (×’×•×“×œ ×ª××•× ×”: {img.shape[1]}x{img.shape[0]})", level=1)

                    results = self.yolo_model(img, verbose=False)[0]

                    # ×‘×“×™×§×” ×©×™×© boxes
                    if not hasattr(results, 'boxes') or results.boxes is None:
                        print_status(f"×œ× × ××¦××• ×¤× ×™× ×‘×ª××•× ×”", level=2)
                        return 0

                    num_faces = len(results.boxes)
                    self.total_faces_detected += num_faces
                    print_status(f"×–×•×”×• {num_faces} ×¤× ×™× ×‘×ª××•× ×”", level=1)

                    faces_saved = 0

                    for i, box in enumerate(results.boxes):
                        try:
                            x1, y1, x2, y2 = map(int, box.xyxy[0])

                            # ×‘×“×™×§×” ×©×”×§×•××•×¨×“×™× ×˜×•×ª ×ª×§×™× ×•×ª
                            if x2 <= x1 or y2 <= y1:
                                print_status(f"×§×•××•×¨×“×™× ×˜×•×ª ×œ× ×ª×§×™× ×•×ª ×¢×‘×•×¨ ×¤× ×™× {i + 1}", level=2, emoji="âš ï¸")
                                continue

                            face_area = (x2 - x1) * (y2 - y1)
                            face = img[y1:y2, x1:x2]

                            # ×‘×“×™×§×” ×©×”×¤× ×™× ×œ× ×¨×™×§×•×ª
                            if face.size == 0:
                                print_status(f"×¤× ×™× ×¨×™×§×•×ª ×¢×‘×•×¨ ×¤× ×™× {i + 1}", level=2, emoji="âš ï¸")
                                continue

                            # ×‘×“×™×§×•×ª ××™×›×•×ª ××¤×•×¨×˜×•×ª
                            size_ok, face_ratio = self.check_face_size(face_area, image_area)
                            sharpness_ok, sharpness = self.check_face_sharpness(face)
                            noise_ok, noise = self.check_face_noise(face)
                            contrast_ok, contrast = self.check_face_contrast(face)

                            # ×“×™×•×•×— ×¢×œ ×‘×“×™×§×•×ª ××™×›×•×ª
                            print_status(f"×¤× ×™× {i + 1}: ×’×•×“×œ={'âœ“' if size_ok else 'âœ—'}({face_ratio:.3f}), " +
                                         f"×—×“×•×ª={'âœ“' if sharpness_ok else 'âœ—'}({sharpness:.0f}), " +
                                         f"×¨×¢×©={'âœ“' if noise_ok else 'âœ—'}({noise:.0f}), " +
                                         f"× ×™×’×•×“×™×•×ª={'âœ“' if contrast_ok else 'âœ—'}({contrast:.0f})", level=2)

                            # ×× ×›×œ ×”×‘×“×™×§×•×ª ×¢×‘×¨×• ×‘×”×¦×œ×—×”
                            if (size_ok and sharpness_ok and noise_ok and contrast_ok):
                                try:
                                    # ×”××¨×ª ×”×ª××•× ×” ×œ-bytes ×œ×”×¢×œ××”
                                    _, img_encoded = cv2.imencode('.jpg', face,
                                                                  [cv2.IMWRITE_JPEG_QUALITY, 95])
                                    img_bytes = img_encoded.tobytes()

                                    # ×™×¦×™×¨×ª ×©× ×™×™×—×•×“×™ ×œ×¤× ×™× ×¢× ×§×™×©×•×¨ ×œ×‘×™×ª ×¡×¤×¨
                                    timestamp = int(datetime.now().timestamp())
                                    face_filename = f"school_{self.school_id}/camera_{self.camera_number}/face_{timestamp}_{i}"

                                    # ×”×¢×œ××” ×œ-Cloudinary
                                    upload_result = cloudinary.uploader.upload(
                                        img_bytes,
                                        public_id=f"extracted_faces/{face_filename}",
                                        resource_type="image",
                                        folder="extracted_faces",
                                        tags=[f"school_{self.school_id}", f"camera_{self.camera_number}"]
                                    )

                                    # ×©××™×¨×ª ×”-public_id ×‘××¢×¨×š
                                    face_public_id = upload_result['public_id']
                                    self.extracted_faces.append(face_public_id)
                                    self.faces_count += 1
                                    self.quality_faces_saved += 1
                                    faces_saved += 1

                                    print_status(f"âœ… ×¤× ×™× ××™×›×•×ª×™×•×ª × ×©××¨×•: {face_public_id}", level=2)

                                except Exception as upload_error:
                                    print_status(f"×©×’×™××” ×‘×”×¢×œ××ª ×¤× ×™×: {str(upload_error)}", level=2, emoji="âš ï¸")
                                    continue

                            else:
                                # ×¤× ×™× ×œ× ×¢×‘×¨×• ×‘×“×™×§×•×ª ××™×›×•×ª
                                failed_checks = []
                                if not size_ok: failed_checks.append("×’×•×“×œ")
                                if not sharpness_ok: failed_checks.append("×—×“×•×ª")
                                if not noise_ok: failed_checks.append("×¨×¢×©")
                                if not contrast_ok: failed_checks.append("× ×™×’×•×“×™×•×ª")

                                print_status(f"×¤× ×™× {i + 1} ×œ× ×¢×‘×¨×• ×‘×“×™×§×•×ª: {', '.join(failed_checks)}",
                                             level=2, emoji="ğŸ”")

                        except Exception as face_error:
                            print_status(f"×©×’×™××” ×‘×¢×™×‘×•×“ ×¤× ×™× {i + 1}: {str(face_error)}", level=2, emoji="âŒ")
                            continue

                    # ×¢×“×›×•×Ÿ ×–××Ÿ ×‘×“×™×§×” ××—×¨×•×Ÿ
                    self.last_detection_time = datetime.now()
                    self.last_updated = datetime.now()

                    # ×¡×™×›×•×
                    improvement = faces_saved - old_faces_count
                    print_status(f"âœ… ×”×•×©×œ× ×—×™×œ×•×¥ ×¤× ×™× ×œ××¦×œ××” {self.camera_number}: " +
                                 f"{faces_saved} ×¤× ×™× ××™×›×•×ª×™×•×ª × ×©××¨×• " +
                                 f"({'+' if improvement >= 0 else ''}{improvement} ×™×—×¡×™×ª ×œ×§×•×“×)", level=1)

                    return faces_saved

                except Exception as img_error:
                    print_status(f"×©×’×™××” ×‘×¢×™×‘×•×“ ×”×ª××•× ×”: {str(img_error)}", emoji="âš ï¸")
                    return 0
            else:
                print_status("âš ï¸ ×¤×•×¨××˜ URL ×œ× × ×ª××š ×œ×—×™×œ×•×¥ ×¤× ×™×", emoji="âŒ")
                return 0

        except Exception as e:
            print_status(f"×©×’×™××” ×›×œ×œ×™×ª ×‘×—×™×œ×•×¥ ×¤× ×™×: {str(e)}", emoji="âŒ")
            return 0

    # --- ×¤×•× ×§×¦×™×•×ª ×§×™×™××•×ª ×¢× ×©×™×¤×•×¨×™× ---

    def get_image_url(self):
        """××—×–×™×¨ URL ×©×œ ×”×ª××•× ×”"""
        return self.image_url

    def get_faces_count(self):
        """××—×–×™×¨ ××¡×¤×¨ ×¤× ×™× ×©×—×•×œ×¦×•"""
        return self.faces_count

    def get_extracted_faces_urls(self):
        """××—×–×™×¨ ×¨×©×™××ª URLs ×©×œ ×¤× ×™× ×©×—×•×œ×¦×•"""
        return self.extracted_faces

    def get_detection_stats(self):
        """×§×‘×œ×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×–×™×”×•×™"""
        return {
            "total_detected": self.total_faces_detected,
            "quality_saved": self.quality_faces_saved,
            "current_faces": self.faces_count,
            "detection_rate": (self.quality_faces_saved / max(1, self.total_faces_detected)) * 100,
            "last_detection": self.last_detection_time.strftime(
                "%d/%m/%Y %H:%M") if self.last_detection_time else "×œ× ×‘×•×¦×¢",
            "model_loaded": self.yolo_model is not None
        }

    def clear_extracted_faces(self):
        """× ×™×§×•×™ ×¤× ×™× ×©×—×•×œ×¦×• (××‘×œ×™ ×œ××—×•×§ ××”×¢× ×Ÿ)"""
        self.extracted_faces = []
        self.faces_count = 0
        self.last_updated = datetime.now()
        print_status(f"ğŸ§¹ × ×•×§×• ×¤× ×™× ×©××•×¨×™× ×¢×‘×•×¨ ××¦×œ××” {self.camera_number}")

    def delete_extracted_faces_from_cloud(self):
        """××—×™×§×ª ×¤× ×™× ×©×—×•×œ×¦×• ××”×¢× ×Ÿ"""
        try:
            deleted_count = 0
            for face_id in self.extracted_faces:
                try:
                    cloudinary.uploader.destroy(face_id)
                    deleted_count += 1
                except:
                    pass  # ×××©×™×š ×× ×™×© ×©×’×™××” ×‘××—×™×§×ª ×¤× ×™× ×¡×¤×¦×™×¤×™×•×ª

            self.extracted_faces = []
            self.faces_count = 0
            self.last_updated = datetime.now()

            print_status(f"ğŸ—‘ï¸ × ××—×§×• {deleted_count} ×¤× ×™× ××”×¢× ×Ÿ ×¢×‘×•×¨ ××¦×œ××” {self.camera_number}")
            return deleted_count

        except Exception as e:
            print_status(f"âŒ ×©×’×™××” ×‘××—×™×§×ª ×¤× ×™× ××”×¢× ×Ÿ: {str(e)}")
            return 0

    def export_to_dict(self):
        """×™×™×¦×•× ×œ×“×™×§×©× ×¨×™ ×œ×©××™×¨×”"""
        return {
            "basic_info": {
                "camera_number": self.camera_number,
                "school_id": self.school_id,
                "camera_location": self.camera_location,
                "camera_description": self.camera_description,
                "is_active": self.is_active
            },
            "images": {
                "image_url": self.image_url,
                "image_urls": self.image_urls
            },
            "face_data": {
                "faces_count": self.faces_count,
                "extracted_faces": self.extracted_faces,
                "total_detected": self.total_faces_detected,
                "quality_saved": self.quality_faces_saved
            },
            "timestamps": {
                "created_at": self.created_at.isoformat(),
                "last_updated": self.last_updated.isoformat(),
                "last_detection": self.last_detection_time.isoformat() if self.last_detection_time else None
            },
            "status": {
                "is_checked": self.is_checked
            }
        }

    @classmethod
    def create_from_dict(cls, data_dict):
        """×™×¦×™×¨×ª ××˜×¨×” ××“×™×§×©× ×¨×™"""
        basic = data_dict.get("basic_info", {})
        images = data_dict.get("images", {})
        face_data = data_dict.get("face_data", {})
        timestamps = data_dict.get("timestamps", {})
        status = data_dict.get("status", {})

        # ×™×¦×™×¨×ª ××˜×¨×”
        target = cls(
            camera_number=basic.get("camera_number"),
            images_url=images.get("image_url"),
            school_id=basic.get("school_id"),
            enable_face_detection=False
        )

        # ×¢×“×›×•×Ÿ × ×ª×•× ×™×
        target.camera_location = basic.get("camera_location", "")
        target.camera_description = basic.get("camera_description", "")
        target.is_active = basic.get("is_active", True)

        target.faces_count = face_data.get("faces_count", 0)
        target.extracted_faces = face_data.get("extracted_faces", [])
        target.total_faces_detected = face_data.get("total_detected", 0)
        target.quality_faces_saved = face_data.get("quality_saved", 0)

        target.is_checked = status.get("is_checked", False)

        # ×¢×“×›×•×Ÿ ×ª××¨×™×›×™×
        try:
            if timestamps.get("created_at"):
                target.created_at = datetime.fromisoformat(timestamps["created_at"])
            if timestamps.get("last_updated"):
                target.last_updated = datetime.fromisoformat(timestamps["last_updated"])
            if timestamps.get("last_detection"):
                target.last_detection_time = datetime.fromisoformat(timestamps["last_detection"])
        except:
            pass

        return target

    def __str__(self):
        status = "×¤×¢×™×œ×”" if self.is_active else "×œ× ×¤×¢×™×œ×”"
        return f"Target(camera={self.camera_number}, school={self.school_id}, faces={self.faces_count}, status={status})"

    def __repr__(self):
        return self.__str__()

    def __eq__(self, other):
        """×”×©×•×•××” ×‘×™×Ÿ ××˜×¨×•×ª ×œ×¤×™ ××¡×¤×¨ ××¦×œ××” ×•×‘×™×ª ×¡×¤×¨"""
        if not isinstance(other, Target):
            return False
        return self.camera_number == other.camera_number and self.school_id == other.school_id

    def __hash__(self):
        """×××¤×©×¨ ×©×™××•×© ×‘××˜×¨×” ×›××¤×ª×— ×‘×“×™×§×©× ×¨×™ ××• ×‘×¡×˜"""
        return hash((self.camera_number, self.school_id))